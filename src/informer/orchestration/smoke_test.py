"""Offline smoke test orchestration for JARVIS.

This module defines a helper to run a deterministic, end‑to‑end
verification of the JARVIS pipeline using a local SQLite database.
The smoke test exercises database migrations, health checks,
the daily scan orchestrator and the DST‑safe scheduler without
requiring any network connectivity or API keys.  It is intended
to provide confidence that a fresh install of JARVIS is
functioning correctly on a local machine (e.g. a Windows laptop).

The `run_smoke_test` function is invoked by the CLI command
``jarvis smoke-test``.  It returns a boolean indicating overall
success and prints a concise summary of each step and elapsed
time.  When ``keep`` is false the temporary SQLite file is
deleted at the end of the run.
"""

from __future__ import annotations

import datetime as _dt
import os
import time
from pathlib import Path
from typing import Optional, Tuple, List

from informer.cli import db_init  # reuse the Click-registered function
from informer.orchestration.daily_scan import run_daily_scan
from informer.orchestration.scheduler import run_scheduler
from informer.db.session import get_engine
from informer.health.checks import build_health_report
from informer.charts.renderer import CHART_VERSION_DEFAULT
from informer.providers.alpaca import PROVIDER_VERSION
from informer.cli import _default_whitelist, _default_timeframes


def _healthcheck_pass(engine, run_id: str) -> bool:
    """Return True if the healthcheck passes without errors.

    A healthcheck passes when the resulting status is not
    ``"NOT_READY"``.  This helper constructs a minimal set of
    parameters required by :func:`build_health_report` and
    executes it.  It does not write any report to disk.
    """
    try:
        symbols: List[str] = _default_whitelist()
        timeframes: List[str] = _default_timeframes()
        report = build_health_report(
            engine=engine,
            run_id=run_id,
            schema_version="v0.1",
            feature_version="v0.1",
            chart_version=CHART_VERSION_DEFAULT,
            provider_version=PROVIDER_VERSION,
            artifacts_root=Path("artifacts"),
            symbols=symbols,
            timeframes=timeframes,
            strict=True,
        )
        return report.status != "NOT_READY"
    except Exception:
        return False


def run_smoke_test(
    *,
    db_path: str = "jarvis_smoke.db",
    run_id: Optional[str] = None,
    keep: bool = True,
) -> bool:
    """Run an offline smoke test of the core JARVIS pipeline.

    Parameters
    ----------
    db_path : str, optional
        Filesystem path to the SQLite database used for the smoke test.
        Defaults to ``"jarvis_smoke.db"`` in the current working
        directory.
    run_id : str, optional
        Identifier for the smoke test run.  If omitted, a timestamp
        of the form ``"smoke_YYYYMMDDHHMMSS"`` is generated.
    keep : bool, optional
        If false, the SQLite file at ``db_path`` is deleted at the
        end of the smoke test.  Artifacts generated by the daily
        scan (packets, decisions, etc.) are retained regardless.

    Returns
    -------
    bool
        True if all steps succeed; False otherwise.

    The function prints a summary of each step and its duration and
    returns whether the overall smoke test passed.  It never
    raises an exception; failures are captured and reported via
    the return value and printed summary.
    """
    # Determine run ID
    if not run_id:
        run_id = "smoke_" + _dt.datetime.utcnow().strftime("%Y%m%d%H%M%S")
    # Prepare environment: set DATABASE_URL to the SQLite file
    prev_db_url = os.environ.get("DATABASE_URL")
    os.environ["DATABASE_URL"] = f"sqlite:///{db_path}"
    # Ensure the database file does not pre‑exist to avoid stale
    # schema state.  If deletion fails we proceed anyway; db_init
    # will recreate or reuse the file as needed.
    try:
        if os.path.exists(db_path):
            os.remove(db_path)
    except Exception:
        pass
    # Collect results and timings
    step_results: List[Tuple[str, bool, float]] = []
    total_start = time.perf_counter()
    try:
        # Step 1: Database initialization
        t0 = time.perf_counter()
        ok = True
        try:
            db_init()
        except Exception:
            ok = False
        duration = time.perf_counter() - t0
        step_results.append(("db-init", ok, duration))
        # Step 2: Healthcheck (strict)
        t0 = time.perf_counter()
        ok_hc = True
        try:
            # Acquire engine if possible; if creation fails healthcheck will fail
            engine = None
            try:
                engine = get_engine()
            except Exception:
                engine = None
            ok_hc = _healthcheck_pass(engine, run_id)
        except Exception:
            ok_hc = False
        duration = time.perf_counter() - t0
        step_results.append(("healthcheck", ok_hc, duration))
        # Step 3: Daily scan (shadow mode)
        t0 = time.perf_counter()
        ok_scan = True
        try:
            run_daily_scan(run_id=run_id, as_of=None, run_mode="shadow", runner=None)
            # Verify that a decision file exists
            decision_path = os.path.join("artifacts", "decisions", f"{run_id}.json")
            ok_scan = ok_scan and os.path.exists(decision_path)
        except Exception:
            ok_scan = False
        duration = time.perf_counter() - t0
        step_results.append(("daily-scan", ok_scan, duration))
        # Step 4: Scheduler dry-run
        t0 = time.perf_counter()
        ok_sched = True
        try:
            # Run scheduler once with dry-run to compute next run time
            run_scheduler(once=True, dry_run=True)
        except Exception:
            ok_sched = False
        duration = time.perf_counter() - t0
        step_results.append(("scheduler", ok_sched, duration))
    finally:
        # Optionally delete the SQLite file
        if not keep:
            try:
                if os.path.exists(db_path):
                    os.remove(db_path)
            except Exception:
                pass
        # Restore previous DATABASE_URL
        if prev_db_url is None:
            os.environ.pop("DATABASE_URL", None)
        else:
            os.environ["DATABASE_URL"] = prev_db_url
    # Compute overall result and print summary
    overall = all(res for _, res, _ in step_results)
    total_duration = time.perf_counter() - total_start
    print("Smoke Test Summary:")
    for name, res, duration in step_results:
        status_str = "PASS" if res else "FAIL"
        print(f" - {name}: {status_str} ({duration:.2f}s)")
    print(f"Overall: {'PASS' if overall else 'FAIL'} ({total_duration:.2f}s)")
    return overall